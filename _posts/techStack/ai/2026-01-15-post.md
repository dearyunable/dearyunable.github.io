---
title: "이미지 기반 어종 식별 및 정보 제공 서비스 만들기 (두번째 기록)"
excerpt: "CNN 기본 개념 학습하기"
categories: [techStack, ai]
tags: [AI, CNN, Convolution, 합성곱, Feature Map, Pooling]
last_modified_at: 2026-01-15T17:27:00+09:00
toc: true
toc_sticky: true
author_profile: true
sidebar:
    nav: "docs"
search: true
---

나는 자바 개발자라서 파이썬, AI에 대해 잘 알지 못한다.  
그래서 먼저, CNN의 전반적인 처리과정을 이해하기 위해서  
비교적 가벼운 모델과 간단한 데이터셋을 활용하여 구현해보았다.  

이 글은 비전문가가 이해하기 어려운 개념들을 쉽게 이해하기 위해 작성하였고,  
CNN에 대한 깊이있는 학습을 하기 전, 빨리 개념을 습득하고 작은 프로젝트를 구현해보고자하면  
참고하기 좋을 것 같다.  

그럼 본론으로 들어가겠다.  
먼저, 이미지, 비디오 같은 시각 데이터를 분석하는 데 특화된 모델인 CNN에 대해서 알아보자.  

<br>
## CNN이란?
먼저, 우리는 이미지를 보고 물고기 사진, 색 있고, 모양 있고, 예쁘다 라고 판단하지만  
컴퓨터가 보는 이미지는 "픽셀들의 집합", "각 픽셀은 숫자" 라는 것을 알고있어야 한다.  

CNN은 이미지에서 *"특징을 자동으로 찾아내는" 인공신경망*이다.  
쉽게 말하면 이미지 내 객체의 선, 모서리, 무늬, 형태를 단계적으로 이해하는 구조이다.  
CNN이 이미지를 보는 방식은 사람처럼 한 번에 보는 것이 아니라, 작은 영역씩 훑어보며 특징을 찾는다.  
마치 사진을 작은 돋보기로 조금씩 훑어보는 느낌이다.
  
이미지를 "숫자로 된 큰 격자" 라고 생각해보자.  
CNN은 이걸 한 번에 보지 않고, [3x3 영역] → 검사 → [다음 3x3 영역] → 검사 → [또 다음 3x3 영역]  
이렇게 슬라이딩하면서 훑는다.  
<br>

# [CNN의 핵심 구성 요소 3가지]
## 1.Convolution (합성곱)
*합성곱은 이미지에서 선, 경계, 방향, 질감같은 "형태적 특징"을 찾아내는 계산 방법*이다.  
CNN에서 합성곱을 수행할 때 사용하는 핵심 도구가 바로 필터(Filter, 또는 Kernel) 이다.  

### - 필터
*필터란 아주 작은 숫자 행렬*이다.  
보통 3×3 크기를 사용하며, 각 숫자는 가중치(weight) 역할을 한다.  
예를 들어, 아래와 같은 필터가 있다고 가정해보자.  
`-1   0   1`  
`-1   0   1`  
`-1   0   1`  

이 숫자들은 사람이 직접 의미를 부여한 값이 아니라,  
“이 방향의 변화가 얼마나 강한가”를 계산하기 위한 가중치라고 이해하면 된다.  
CNN이 학습 과정에서 스스로 만들어낸 결과다.  

### - 합성곱 계산 과정
**(1) 이미지의 작은 영역을 가져온다.**  
CNN은 이미지를 한 번에 보지 않고, 3×3 같은 작은 영역씩 잘라서 본다.  

예를 들어, 이미지의 한 부분이 아래와 같다고 하자. (숫자는 픽셀의 밝기 값이라고 생각하면 된다)  
`10   10   200`  
`10   10   200`  
`10   10   200`  

**(2) 필터를 이미지 위에 겹친다**  
이미지의 3×3 영역과 필터를 같은 위치에 겹친다.  

|이미지 일부|필터|
|:---:|:---:|
|10  10  200|-1 0 1|
|10  10  200|-1 0 1|
|10  10  200|-1 0 1|

**(3) 같은 위치끼리 곱한 뒤, 전부 더한다**  
이제 같은 위치의 숫자끼리 곱하고, 그 결과를 모두 더해서 하나의 값을 만든다.  

계산을 풀어서 쓰면 다음과 같다.  
(10 × -1) + (10 × 0) + (200 × 1)  
\+ (10 × -1) + (10 × 0) + (200 × 1)  
\+ (10 × -1) + (10 × 0) + (200 × 1)  

여기서 중요한 점은  
CNN은 이걸 줄별로 따로 판단하지 않는다.  
3×3 전체를 하나의 덩어리로 계산해서 최종 결과 값 하나만 만든다.  

**\- 이 숫자 190이 의미하는 것**  
이 계산을 말로 풀면 다음과 같다.  
“오른쪽 밝기(200)가 왼쪽 밝기(10)보다 훨씬 크다”  
즉, 왼쪽은 어둡고 오른쪽은 밝다, 좌우 밝기 차이가 크다.  

CNN은 이를 이렇게 해석한다.  
“이 위치에는 좌우로 강하게 갈라진 경계(세로 방향 경계)가 있다.”  

이처럼 결과 값이 클수록, 해당 필터가 찾는 패턴이 강하게 존재한다는 뜻이다.

**\- 짚고 넘어가야 할 핵심 정리**  
**(1) 필터 값은 사람이 정하지 않는다.**  
처음에는 필터 값이 거의 랜덤에 가깝다.  
이미지를 넣고 예측 → 틀림 → 수정  
이 과정을 반복하면서 CNN이 스스로 “쓸모 있는 필터”를 만들어낸다.  

**(2) CNN은 줄별로 판단하지 않는다**  
(10×-1) 같은 계산이 여러 줄로 보이지만 실제로는 3×3 전체를 한 번에 계산한다.  
결과는 숫자 하나, 이 숫자가 Feature Map의 한 칸이 된다.  

이 단계에서는 "물고기"를 모른다. 오직, 선이 있는지, 경계가 강한지, 방향성이 있는지 등 아주 기초적인 형태 조각만 감지한다.
<br>

## 2.Feature Map (특징 지도)
앞에서 합성곱(Convolution)을 통해 하나의 위치에 대한 하나의 숫자가 만들어진다고 했었다.  
그럼 "이미지 전체를 훑으면 숫자 하나만 나오나?"  
~~아니다.~~  
합성곱 필터는 이미지 한 위치만 보는 게 아니라, 이미지 전체를 위에서 아래로,  
왼쪽에서 오른쪽으로 이동하면서 계산한다. 
즉, 이미지의 첫 번째 3x3 영역 -> 숫자 1개  
옆으로 한 칸 이동 -> 숫자 1개  
또 이동 -> 숫자 1개  
... *끝까지 반복해서 만들어진 숫자들의 모임이 바로 Feature Map (특징 맵)* 이다.  

쉽게 말하면 "이 필터가 이미지 어디에서 강하게 반응했는지를 나타낸 지도" 이다.  
값이 크다 → 이 위치에 필터가 찾는 패턴이 강함.  
값이 작거나 0에 가깝다 → 거의 반응하지 않음.  

여기서 중요한 사실은  
필터 하나 = Feature Map 하나 라는 것.  
필터는 처음에는 의미 없는 숫자 덩어리지만, 학습이 진행되면서 어떤 필터는 세로선에,  
어떤 필터는 가로선이나 곡선, 질감에 강하게 반응하도록 스스로 학습된다.  
각 필터는 자기 Feature Map을 생성하는 것이다.  
(필터는 “검사 기준”이고, Feature Map은 그 기준으로 검사한 “결과표”다.  
그래서 필터 1개는 Feature Map 1개를 만든다.)  

## 3.Pooling
이제 Feature Map이 만들어졌다.  
근데 Feature Map 크기가 너무 크고 계산량도 많고 위치가 조금만 달라져도 값이 바뀐다.  
그래서 등장한 단계가 바로 Pooling(풀링)이다.  

### - Pooling의 목적
1.Feature Map 크기 줄이기 (연산량 감소)  
2.중요한 특징만 남기기  
3.위치 변화에 둔감하게 만들기  

Pooling을 한 줄로 말하면 "근처 값들 중에서 대표값 하나만 남기는 작업" 이다.  

보통 Max Pooling을 사용한다.  
Feature Map 일부가 아래와 같다고 하자.  
`1 3`  
`2 5`   
2x2 영역에서 가장 큰 값인 5만 남긴다. 즉, 작은 값은 버리고 가장 강한 반응만 유지한다.  

Convolution는 학습을 통해 가중치가 생성되지만  
Pooling은 룰만 존재한다. 즉, 같은 고정된 규칙을 적용할 뿐이다.  

### - feature Map + Pooling 흐름 요약
이미지 -> CNN 내부에서는 이렇게 흘러간다.  

입력 이미지  
 &nbsp; &nbsp; &nbsp; &nbsp;↓  
합성곱 (필터 적용)  
 &nbsp; &nbsp; &nbsp; &nbsp;↓  
Feature Map (패턴 지도)  
 &nbsp; &nbsp; &nbsp; &nbsp;↓  
Pooling (요약, 축소)  
 &nbsp; &nbsp; &nbsp; &nbsp;↓  
더 깊은 합성곱  
 &nbsp; &nbsp; &nbsp; &nbsp;↓  
더 추상적인 Feature Map  

단계가 깊어질수록   
초반 Feature Map → 선, 경계, 방향  
중간 Feature Map → 지느러미 형태, 몸통 윤곽  
후반 Feature Map → 연어·명태를 구분하는 데 필요한 고수준 특징  
이렇게 점점 추상화된다.  

이렇게 학습된 가중치를 가진 Feature Extractor는  
다양한 이미지에서도 기본적인 시각적 특징을 잘 추출할 수 있다.  

Feature Extractor는  
CNN이 만들어낸 모든 중간 Feature Map들을 포함하는 개념이며,  
분류 모델은 그중 마지막 것만 사용하고,  
객체 탐지 모델은 여러 단계의 Feature Map을 꺼내서 사용한다.  

우리는 이 Feature Extractor를 그대로 활용하고,  
마지막 분류기(Classifier) 층만 수정하여  
어류 분류 문제에 맞게 재학습한다.  

이로써 CNN 기반 분류 모델의 기본 구조와 학습 흐름을 정리해본다.   